{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\etaxi\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In C:\\Users\\etaxi\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In C:\\Users\\etaxi\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n"
     ]
    }
   ],
   "source": [
    "from Classify_Symbols.classify_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, '..\\\\data')\n",
    "data_folder = 'lab-03-data'\n",
    "tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "    tar.extractall(path=data_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, image_shape, image_number):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(np.prod(image_shape) * image_number)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(image_number, image_shape[0], image_shape[1])\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_labels(filename, image_number):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * image_number)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (28, 28)\n",
    "train_set_size = 60000\n",
    "test_set_size = 10000\n",
    "\n",
    "data_part2_folder = os.path.join(data_base_path, data_folder, 'part2')\n",
    "\n",
    "train_images_path = os.path.join(data_part2_folder, 'train-images-idx3-ubyte.gz')\n",
    "train_labels_path = os.path.join(data_part2_folder, 'train-labels-idx1-ubyte.gz')\n",
    "test_images_path = os.path.join(data_part2_folder, 't10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = os.path.join(data_part2_folder, 't10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "train_images = extract_data(train_images_path, image_shape, train_set_size)\n",
    "test_images = extract_data(test_images_path, image_shape, test_set_size)\n",
    "train_labels = extract_labels(train_labels_path, train_set_size)\n",
    "test_labels = extract_labels(test_labels_path, test_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n",
      "(60000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape, test_images.shape)\n",
    "print(train_labels.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading pictures as Kilian feeds them to me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24f59982b38>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Can be loaded using pickle and the following lines\n",
    "with open('extractedImg.data', 'rb') as dataFile:\n",
    "\tlistObj = pickle.load(dataFile)\n",
    "    \n",
    "digits = [listObj[i]['img'] for i in [0,1,4,5,7,8] ]#just keep the digits (and discard the symbols)\n",
    "plt.imshow(digits[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "#keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "(X_train, y_train), (X_test, y_test) = (train_images, train_labels), (test_images, test_labels)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def FCN():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu',\n",
    "                   kernel_regularizer=keras.regularizers.l1_l2(l1=0.00, l2=0.00) ))\n",
    "    #model.add(Dense(int(num_pixels/4), input_dim=num_pixels, kernel_initializer='normal', activation='relu',\n",
    "    #               kernel_regularizer=keras.regularizers.l1_l2(l1=0.00, l2=0.01)   ))\n",
    "    model.add(Dense(num_classes+1, kernel_initializer='normal', activation='softmax',\n",
    "                   kernel_regularizer=keras.regularizers.l1_l2(l1=0.00, l2=0.00) ))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 11)                8635      \n",
      "=================================================================\n",
      "Total params: 624,075\n",
      "Trainable params: 624,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_4 to have shape (11,) but got array with shape (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8f3377c8e3b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# Final evaluation of the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_4 to have shape (11,) but got array with shape (10,)"
     ]
    }
   ],
   "source": [
    "model = FCN()\n",
    "model.summary() #show the current structure of the network\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "h = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(h.history.keys())\n",
    "accuracy = h.history['acc']\n",
    "val_accuracy = h.history['val_acc']\n",
    "loss = h.history['loss']\n",
    "val_loss = h.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'blue', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'orange', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'blue', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'orange', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN first try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,                \n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation function (relu, sigmoid, etc.)\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    #2 possibilities : \n",
    "    # 1) First convolute, then normalize\n",
    "    # 2) First normalize, then convolute\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(inputs, nb_filters_out = 32 , activation = 'relu', batch_normalization = 'true', kernel_size = 5):\n",
    "    \"\"\"Residual_block\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    #Need to remove this from here later\n",
    "    strides = 1\n",
    "    kernel_size_res = 1\n",
    "    \n",
    "    # x = residual of the block\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=nb_filters_out,\n",
    "                     kernel_size=kernel_size_res,\n",
    "                     strides=strides,\n",
    "                     activation=None,\n",
    "                     batch_normalization=batch_normalization,\n",
    "                     conv_first=False)\n",
    "    \n",
    "    # y = picture we transform in the block\n",
    "    y = resnet_layer(inputs=inputs,\n",
    "                     num_filters=nb_filters_out,\n",
    "                     kernel_size=kernel_size,\n",
    "                     strides=strides,\n",
    "                     activation=activation,\n",
    "                     batch_normalization=batch_normalization,\n",
    "                     conv_first=True)\n",
    "    y = resnet_layer(inputs=y,\n",
    "                     num_filters=nb_filters_out,\n",
    "                     kernel_size=kernel_size,\n",
    "                     strides=strides,\n",
    "                     activation=activation,\n",
    "                     batch_normalization=batch_normalization,\n",
    "                     conv_first=True)\n",
    "    y = resnet_layer(inputs=y,\n",
    "                     num_filters=nb_filters_out,\n",
    "                     kernel_size=kernel_size,\n",
    "                     strides=strides,\n",
    "                     activation=None,\n",
    "                     batch_normalization=batch_normalization,\n",
    "                     conv_first=True)\n",
    "    \n",
    "    x = keras.layers.add([x, y])\n",
    "    x = resnet_layer(inputs = x,          \n",
    "                    num_filters = nb_filters_out, #For now, the whole block will end up with nb_filters_out filters\n",
    "                    kernel_size = kernel_size,\n",
    "                    strides = strides,\n",
    "                    activation = activation, #Before : None\n",
    "                    batch_normalization = False)\n",
    "\n",
    "    return x \n",
    "    \n",
    "    #Instatiate model : \n",
    "    #model = Model(inputs=inputs, outputs=x)\n",
    "    #return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_resnet_resnet(input_shape, depth):\n",
    "    \"\"\"Residual_block\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "        \n",
    "    Stucture :\n",
    "    \n",
    "    inputs --> RESNET (regression) --> x --> RESNET (classification) --> y\n",
    "    outputs = [x,y]\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    activation = 'relu'\n",
    "    batch_normalization = True\n",
    "    strides = 1\n",
    "    my_kernel_size = 5                      # I CHANGED TO 5\n",
    "    \n",
    "   \n",
    "    #filters = [16, 24, 24, 32, 32, 24, 24, 16, 1]  #As in the papers\n",
    "    filters = [24, 32, 32, 32, 32, 32, 32, 24, 1] #a test ----- struct2\n",
    "    #filters = [16, 16, 24, 24, 24, 24, 32, 32, 24, 24, 16, 16, 1] #Try1\n",
    "    \n",
    "    # inputs = original picture entry\n",
    "    x = inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # -------------- RESNET (regression) --------------------\n",
    "    #apply a sequence of residual networks \n",
    "    for fil in filters:\n",
    "      x = residual_block(x, nb_filters_out = fil, kernel_size= my_kernel_size)\n",
    "      \n",
    "    # -------------- RESNET (classification )-----------------\n",
    "    filters_K = filters #same as the first prediction part\n",
    "    y = x #we keep the output of the first ResNet into x\n",
    "    \n",
    "    for fil in filters_K:\n",
    "      y = residual_block(y, nb_filters_out = fil, kernel_size= my_kernel_size)\n",
    "    y = Dense(K, activation='softmax', kernel_initializer='he_normal')(y) #K = nb_class\n",
    "    \n",
    "    #Instantiate the model\n",
    "    model = Model(inputs=inputs, outputs=[x,y])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_input_shape = (28,28,1)\n",
    "the_inputs = Input(shape=the_input_shape)\n",
    "output1 = residual_block( the_inputs, nb_filters_out = 24, kernel_size = 5 )\n",
    "\n",
    "model = Model(inputs=the_inputs, outputs= output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-d672b1e862fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Final evaluation of the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Baseline Error: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[0;32m    682\u001b[0m                                    \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Failed to convert object of type <class 'tuple'> to Tensor. Contents: (1, <module 'keras.backend' from 'C:\\\\Users\\\\etaxi\\\\Anaconda3\\\\envs\\\\keras-gpu\\\\lib\\\\site-packages\\\\keras\\\\backend\\\\__init__.py'>). Consider casting elements to a supported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m       \u001b[0mstr_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m       \u001b[0mstr_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\util\\compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[1;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[0;32m     60\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[1;32m---> 61\u001b[1;33m                     (bytes_or_text,))\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected binary or unicode string, got 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-5d18dc81c579>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomplete_resnet_resnet\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m56\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#model.summary() #show the current structure of the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-70-77dc0d71d7ce>\u001b[0m in \u001b[0;36mcomplete_resnet_resnet\u001b[1;34m(input_shape, depth)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfil\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilters_K\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m       \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresidual_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_filters_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfil\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmy_kernel_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'he_normal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#K = nb_class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m#Instantiate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m                                          \u001b[1;34m'You can build it manually via: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m--> 431\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    864\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'kernel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[0;32m    867\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m             self.bias = self.add_weight(shape=(self.units,),\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         weight = K.variable(initializer(shape),\n\u001b[0m\u001b[0;32m    250\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype)\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[0mstddev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m.87962566103423978\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             return K.truncated_normal(shape, 0., stddev,\n\u001b[1;32m--> 214\u001b[1;33m                                       dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mtruncated_normal\u001b[1;34m(shape, mean, stddev, dtype, seed)\u001b[0m\n\u001b[0;32m   4183\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4184\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10e6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4185\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mtruncated_normal\u001b[1;34m(shape, mean, stddev, dtype, seed, name)\u001b[0m\n\u001b[0;32m    171\u001b[0m   \"\"\"\n\u001b[0;32m    172\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"truncated_normal\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[0mshape_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ShapeTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[0mmean_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[0mstddev_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"stddev\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36m_ShapeTensor\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m     42\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m   \"\"\"\n\u001b[1;32m-> 1039\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1095\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1097\u001b[1;33m       as_ref=False)\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    302\u001b[0m                                          as_ref=False):\n\u001b[0;32m    303\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    243\u001b[0m   \"\"\"\n\u001b[0;32m    244\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 245\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m    282\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[0;32m    284\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    560\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[0;32m    561\u001b[0m                       \u001b[1;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[0;32m    563\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (1, <module 'keras.backend' from 'C:\\\\Users\\\\etaxi\\\\Anaconda3\\\\envs\\\\keras-gpu\\\\lib\\\\site-packages\\\\keras\\\\backend\\\\__init__.py'>). Consider casting elements to a supported type."
     ]
    }
   ],
   "source": [
    "# ======================  see later that\n",
    "\n",
    "\n",
    "model = complete_resnet_resnet( (28, 28, 1), 56 )\n",
    "#model.summary() #show the current structure of the network\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "h = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start over here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_input_shape = (28,28,1)\n",
    "CNN_inputs = Input(shape=CNN_input_shape)\n",
    "\n",
    "# start building the CNN structure \n",
    "strides = 1\n",
    "kernel_size_res = 1\n",
    "nb_filters_out = 32\n",
    "batch_normalization = False\n",
    "\n",
    "# x = residual of the block\n",
    "x = resnet_layer(inputs=CNN_inputs,\n",
    "                 num_filters=nb_filters_out,\n",
    "                 kernel_size=kernel_size_res,\n",
    "                 strides=strides,\n",
    "                 activation=None,\n",
    "                 batch_normalization=batch_normalization,\n",
    "                 conv_first=False)\n",
    "\n",
    "# y = picture we transform in the block\n",
    "y = resnet_layer(inputs=CNN_inputs,\n",
    "                 num_filters=nb_filters_out,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=strides,\n",
    "                 activation=activation,\n",
    "                 batch_normalization=batch_normalization,\n",
    "                 conv_first=True)\n",
    "y = resnet_layer(inputs=y,\n",
    "                 num_filters=nb_filters_out,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=strides,\n",
    "                 activation=activation,\n",
    "                 batch_normalization=batch_normalization,\n",
    "                 conv_first=True)\n",
    "y = resnet_layer(inputs=y,\n",
    "                 num_filters=nb_filters_out,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=strides,\n",
    "                 activation=None,\n",
    "                 batch_normalization=batch_normalization,\n",
    "                 conv_first=True)\n",
    "\n",
    "x = keras.layers.add([x, y])\n",
    "x = resnet_layer(inputs = x,          \n",
    "                num_filters = nb_filters_out, #For now, the whole block will end up with nb_filters_out filters\n",
    "                kernel_size = kernel_size,\n",
    "                strides = strides,\n",
    "                activation = activation, #Before : None\n",
    "                batch_normalization = False)\n",
    "x = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# end of CNN structure\n",
    "output1 = residual_block( the_inputs, nb_filters_out = 24, kernel_size = 5 )\n",
    "\n",
    "model = Model(inputs=the_inputs, outputs= output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(inputs, nb_filters_out = 32 , activation = 'relu', batch_normalization = 'true', kernel_size = 5):\n",
    "    \"\"\"Residual_block\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    #Need to remove this from here later\n",
    "    strides = 1\n",
    "    kernel_size_res = 1\n",
    "    \n",
    "    # x = residual of the block\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=nb_filters_out,\n",
    "                     kernel_size=kernel_size_res,\n",
    "                     strides=strides,\n",
    "                     activation=None,\n",
    "                     batch_normalization=batch_normalization,\n",
    "                     conv_first=False)\n",
    "    \n",
    "    # y = picture we transform in the block\n",
    "    y = resnet_layer(inputs=inputs,\n",
    "                     num_filters=nb_filters_out,\n",
    "                     kernel_size=kernel_size,\n",
    "                     strides=strides,\n",
    "                     activation=activation,\n",
    "                     batch_normalization=batch_normalization,\n",
    "                     conv_first=True)\n",
    "    y = resnet_layer(inputs=y,\n",
    "                     num_filters=nb_filters_out,\n",
    "                     kernel_size=kernel_size,\n",
    "                     strides=strides,\n",
    "                     activation=activation,\n",
    "                     batch_normalization=batch_normalization,\n",
    "                     conv_first=True)\n",
    "    y = resnet_layer(inputs=y,\n",
    "                     num_filters=nb_filters_out,\n",
    "                     kernel_size=kernel_size,\n",
    "                     strides=strides,\n",
    "                     activation=None,\n",
    "                     batch_normalization=batch_normalization,\n",
    "                     conv_first=True)\n",
    "    \n",
    "    x = keras.layers.add([x, y])\n",
    "    x = resnet_layer(inputs = x,          \n",
    "                    num_filters = nb_filters_out, #For now, the whole block will end up with nb_filters_out filters\n",
    "                    kernel_size = kernel_size,\n",
    "                    strides = strides,\n",
    "                    activation = activation, #Before : None\n",
    "                    batch_normalization = False)\n",
    "\n",
    "    return x \n",
    "    \n",
    "    #Instatiate model : \n",
    "    #model = Model(inputs=inputs, outputs=x)\n",
    "    #return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
